
```{r}
library(base64enc)
library(twitteR)
library(ROAuth)
library(RCurl)
library(tm)
library(SnowballC)
library(syuzhet)
library(glue)
library(ggplot2)
library(ggpubr)
library(tidyverse)
library(tidytext)
library (rtweet)
library(ggmap)
library(ggplot2)
library(stringr)
library(wordcloud)
library(lubridate)
library(data.table)
library(reshape2)
```


#Extract the data for PayPal and Google Pay
```{r}
#searchTerm <- "PayPal OR PayPalMobilePayment OR PayPalOnlineMobilePayment"
#trendingTweetsPayPAL = searchTwitter(searchTerm,n=500, lang="en", since="2020-01-01", until="2020-11-24" )

```

```{r}
#searchTerm <- "GooglePay OR GooglePayMobilePayment OR GooglePayOnlineMobilePayment"
#trendingTweetsGooglePay = searchTwitter(searchTerm,n=500, lang="en", since="2020-01-01", until="2020-11-24")

```

# Converting data to dataframe
```{r}
PayPal <- read.csv("PayPal.csv", header=T)
attach(PayPal)
head(PayPal)
```
```{r}
GooglePay <- read.csv("GooglePay.csv", header=T)
attach(GooglePay)
head(GooglePay)
```

```{r}
# remove http elements manually
PayPal$stripped_text<- gsub("http.*","", PayPal$text)
PayPal$stripped_text<- gsub("https.*","", PayPal$stripped_text)
# remove punctuation, convert to lowercase, add id for each tweet
PayPal_clean <- PayPal %>% dplyr::select(stripped_text) %>% unnest_tokens(word,stripped_text)
# remove stop words from your list of words
PayPal_keywords <- PayPal_clean %>% anti_join(stop_words)

```

```{r}
PayPal_keywords %>% count ( word, sort = TRUE ) %>% top_n ( 20 ) %>%
filter ( substr ( word, 1, 1 ) != '#', # omit hashtags
substr ( word, 1, 1 ) != '@', # omit Twitter handles
n > 10 ) %>% # only most common words
mutate ( word = reorder ( word, n )) %>% ggplot ( aes ( word, n, fill = word )) +
geom_bar ( stat = 'identity' ) + xlab ( NULL ) + theme ( legend.position = "none" ) +
coord_flip ( ) + labs ( y = "Count", x = "Keywords",
title = "Keywords Associated with PayPal" )

```

```{r}
PayPal_bing <- PayPal_clean %>% inner_join ( get_sentiments ( "bing" )) %>% count ( word,
sentiment, sort = TRUE ) %>% ungroup ( )
PayPal_bing %>% group_by ( sentiment ) %>% top_n ( 10 ) %>% ungroup ( ) %>%
mutate ( word = reorder ( word, n )) %>% ggplot ( aes ( word, n, fill = sentiment )) +
geom_col ( show.legend = FALSE ) + facet_wrap ( ~sentiment, scales = "free_y" ) +
labs ( title = "Keywords associated with PayPal's negative & positive sentiment", y = "Contribution to Sentiment",
x = NULL ) + coord_flip()
```


```{r}
library(reshape2)
PayPal_clean %>% inner_join(get_sentiments ( "bing" )) %>%
count ( word, sentiment, sort = TRUE ) %>%
acast ( word ~ sentiment, value.var = "n", fill = 0 ) %>%
comparison.cloud ( color = c ( "red", "blue" ), max.words = 100)
```

```{r}
encodeSentiment <- function(x) {
  if(x <= -0.5){
    "Very Negative"
  }else if(x > -0.5 & x < 0){
    "Negative"
  }else if(x > 0 & x < 0.5){
    "Positive"
  }else if(x >= 0.5){
    "Very Positive"
  }else {
    "Neutral"
  }
}
tweetSentiments <- get_sentiment (PayPal$text, method = "syuzhet")
tweets <- cbind(PayPal, tweetSentiments)
tweets$sentiment <- sapply(tweets$tweetSentiments,encodeSentiment)
ggplot(tweets, aes(sentiment)) +
geom_bar(fill = "aquamarine4") +
theme(legend.position="none",
axis.title.x = element_blank()) +
ylab("Number of tweets") +
ggtitle("Tweets by Sentiment")
```


# GooglePay

```{r}
# remove http elements manually
GooglePay$stripped_text<- gsub("http.*","", GooglePay$text)
GooglePay$stripped_text<- gsub("https.*","", GooglePay$stripped_text)
# remove punctuation, convert to lowercase, add id for each tweet
GooglePay_clean <- GooglePay %>% dplyr::select(stripped_text) %>% unnest_tokens(word,stripped_text)
# remove stop words from your list of words
GooglePay_keywords <- GooglePay_clean %>% anti_join(stop_words)

```

```{r}
GooglePay_keywords %>% count ( word, sort = TRUE ) %>% top_n ( 20 ) %>%
filter ( substr ( word, 1, 1 ) != '#', # omit hashtags
substr ( word, 1, 1 ) != '@', # omit Twitter handles
n > 10 ) %>% # only most common words
mutate ( word = reorder ( word, n )) %>% ggplot ( aes ( word, n, fill = word )) +
geom_bar ( stat = 'identity' ) + xlab ( NULL ) + theme ( legend.position = "none" ) +
coord_flip ( ) + labs ( y = "Count", x = "Keywords",
title = "Keywords Associated with GooglePay" )

```

```{r}
GooglePay_bing <- GooglePay_clean %>% inner_join ( get_sentiments ( "bing" )) %>% count ( word,
sentiment, sort = TRUE ) %>% ungroup ( )
GooglePay_bing %>% group_by ( sentiment ) %>% top_n ( 10 ) %>% ungroup ( ) %>%
mutate ( word = reorder ( word, n )) %>% ggplot ( aes ( word, n, fill = sentiment )) +
geom_col ( show.legend = FALSE ) + facet_wrap ( ~sentiment, scales = "free_y" ) +
labs ( title = "Keywords associated with GooglePay's negative & positive sentiment", y = "Contribution to Sentiment",
x = NULL ) + coord_flip()
```


```{r}
library(reshape2)
GooglePay_clean %>% inner_join(get_sentiments ( "bing" )) %>%
count ( word, sentiment, sort = TRUE ) %>%
acast ( word ~ sentiment, value.var = "n", fill = 0 ) %>%
comparison.cloud ( color = c ( "red", "blue" ), max.words = 100)
```

```{r}
encodeSentiment <- function(x) {
  if(x <= -0.5){
    "Very Negative"
  }else if(x > -0.5 & x < 0){
    "Negative"
  }else if(x > 0 & x < 0.5){
    "Positive"
  }else if(x >= 0.5){
    "Very Positive"
  }else {
    "Neutral"
  }
}
tweetSentiments <- get_sentiment (GooglePay$text, method = "syuzhet")
tweets <- cbind(GooglePay, tweetSentiments)
tweets$sentiment <- sapply(tweets$tweetSentiments,encodeSentiment)
ggplot(tweets, aes(sentiment)) +
geom_bar(fill = "aquamarine4") +
theme(legend.position="none",
axis.title.x = element_blank()) +
ylab("Number of tweets") +
ggtitle("Tweets by Sentiment")
```

